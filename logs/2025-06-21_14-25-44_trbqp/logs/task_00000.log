2025-06-21 14:25:45.446 | INFO     | datatrove.utils.logging:add_task_logger:58 - Launching pipeline for rank=0
2025-06-21 14:25:45.447 | INFO     | datatrove.utils.logging:log_pipeline:90 - 
--- 🛠️ PIPELINE 🛠
📖 - READER: 🐿 Jsonl
🔻 - FILTER: 🤖 fastText
💽 - WRITER: 🐿 Jsonl
2025-06-21 14:25:45.452 | INFO     | datatrove.pipeline.readers.base:read_files_shard:201 - Reading input file 00001.jsonl, 1/5
2025-06-21 14:26:04.850 | INFO     | datatrove.pipeline.readers.base:read_files_shard:201 - Reading input file 00003.jsonl, 2/5
2025-06-21 14:26:15.372 | INFO     | datatrove.pipeline.readers.base:read_files_shard:201 - Reading input file 00005.jsonl, 3/5
2025-06-21 14:26:24.859 | INFO     | datatrove.pipeline.readers.base:read_files_shard:201 - Reading input file 00007.jsonl, 4/5
2025-06-21 14:26:37.738 | INFO     | datatrove.pipeline.readers.base:read_files_shard:201 - Reading input file 00009.jsonl, 5/5
2025-06-21 14:26:49.096 | SUCCESS  | datatrove.executor.base:_run_for_rank:98 - Processing done for rank=0
2025-06-21 14:26:49.102 | INFO     | datatrove.executor.base:_run_for_rank:104 - 

📉📉📉 Stats: Task 0 📉📉📉

Total Runtime: 1 minute and 3 seconds

📖 - READER: 🐿 Jsonl
    Runtime: (0.47%) 0 seconds [0.01 milliseconds±0.03 milliseconds/doc]
    Stats: {input_files: 5, doc_len: 170232203 [min=10, max=925386, 3404.64±21362/doc], documents: 50000 [10000.00/input_file]}
🔻 - FILTER: 🤖 fastText
    Runtime: (99.19%) 1 minute and 2 seconds [1.25 milliseconds±48.81 milliseconds/doc]
    Stats: {kept_span: 7611, total: 50000, forwarded: 7611, doc_len: 46186549 [min=10, max=709564, 6068.39±40294/doc], removed_span: 42389, dropped: 42389}
💽 - WRITER: 🐿 Jsonl
    Runtime: (0.34%) 0 seconds [0.03 milliseconds±0.09 milliseconds/doc]
    Stats: {XXXXX.jsonl: 7611, total: 7611, doc_len: 46186549 [min=10, max=709564, 6068.39±40294/doc]}
